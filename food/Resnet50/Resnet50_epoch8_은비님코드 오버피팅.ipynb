{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"10sKYrbghy_lVsR8lmFDPd6ex4w8jcYOC","authorship_tag":"ABX9TyOw655onB+bnKiJ5d1wxxDs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import os\n","import random\n","\n","# Define the list of classes\n","classes = ['보쌈', '볶음면', '비빔밥', '빵']\n","\n","# Define the image size\n","img_size = 256\n","\n","\n","# Define the paths for the training and validation sets\n","train_path = r'/content/drive/MyDrive/음식/'\n","valid_path = r'/content/drive/MyDrive/음식/'\n","\n","# Define the batch size and number of epochs\n","batch_size = 32\n","num_epochs = 8\n","\n","# Load the ResNet50 model\n","base_model = tf.keras.applications.ResNet50(input_shape=(img_size, img_size, 3), include_top=False, weights='imagenet')\n","\n","# Freeze the layers in the base model\n","base_model.trainable = False\n","\n","# Add a classification head to the model\n","model = tf.keras.Sequential([\n","    base_model,\n","    tf.keras.layers.GlobalAveragePooling2D(),\n","    tf.keras.layers.Dense(512, activation='relu'),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.Dense(len(classes), activation='softmax')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Create data generators for the training and validation sets\n","train_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","valid_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n","    rescale=1./255\n",")\n","\n","train_generator = train_data_gen.flow_from_directory(\n","    train_path,\n","    target_size=(img_size, img_size),\n","    batch_size=batch_size,\n","    class_mode='categorical'\n",")\n","\n","valid_generator = valid_data_gen.flow_from_directory(\n","    valid_path,\n","    target_size=(img_size, img_size),\n","    batch_size=batch_size,\n","    class_mode='categorical'\n",")\n","\n","# Train the model\n","history = model.fit(\n","    train_generator,\n","    epochs=num_epochs,\n","    validation_data=valid_generator\n",")\n","\n","# Save the trained model in the models directory\n","model.save('food_classifier_resnet50.js')\n","\n","# Evaluate the model on the validation set\n","loss, accuracy = model.evaluate(valid_generator)\n","\n","# Print the validation accuracy\n","print('Validation accuracy:', accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3njiVS7v49Sq","executionInfo":{"status":"ok","timestamp":1684080919065,"user_tz":-540,"elapsed":852971,"user":{"displayName":"­장희주(엘텍공과대학 휴먼기계바이오공학부)","userId":"05958208042063404683"}},"outputId":"05176aef-40bb-4ad6-b57e-ff709dcad2d2"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94765736/94765736 [==============================] - 5s 0us/step\n","Found 400 images belonging to 4 classes.\n","Found 400 images belonging to 4 classes.\n","Epoch 1/8\n","13/13 [==============================] - 222s 17s/step - loss: 1.6980 - accuracy: 0.2675 - val_loss: 1.3192 - val_accuracy: 0.2900\n","Epoch 2/8\n","13/13 [==============================] - 47s 4s/step - loss: 1.4613 - accuracy: 0.3200 - val_loss: 1.2117 - val_accuracy: 0.4725\n","Epoch 3/8\n","13/13 [==============================] - 47s 4s/step - loss: 1.3580 - accuracy: 0.3550 - val_loss: 1.2476 - val_accuracy: 0.3600\n","Epoch 4/8\n","13/13 [==============================] - 46s 4s/step - loss: 1.3065 - accuracy: 0.3825 - val_loss: 1.2488 - val_accuracy: 0.3675\n","Epoch 5/8\n","13/13 [==============================] - 48s 4s/step - loss: 1.2972 - accuracy: 0.3800 - val_loss: 1.2688 - val_accuracy: 0.4150\n","Epoch 6/8\n","13/13 [==============================] - 46s 4s/step - loss: 1.2976 - accuracy: 0.3900 - val_loss: 1.2219 - val_accuracy: 0.4550\n","Epoch 7/8\n","13/13 [==============================] - 47s 4s/step - loss: 1.2897 - accuracy: 0.3675 - val_loss: 1.1444 - val_accuracy: 0.5150\n","Epoch 8/8\n","13/13 [==============================] - 48s 4s/step - loss: 1.2441 - accuracy: 0.4400 - val_loss: 1.1574 - val_accuracy: 0.5375\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["13/13 [==============================] - 20s 2s/step - loss: 1.1574 - accuracy: 0.5375\n","Validation accuracy: 0.5375000238418579\n"]}]}]}